## VIRTUAL ENV
pyenv activate miniGes

## PROJECT OBJECTIVE
Build a complete end-to-end Indian Sign Language (ISL) recognition application that:
1. âœ… Recognizes 30 ISL word signs from video input
2. ðŸ¤– Uses a transformer model to convert recognized words into grammatically correct sentences
3. ðŸ’» Provides a user-friendly interface for real-time sign language recognition

***

## ðŸ“Š DATASET
- **Source**: INCLUDE Dataset (Zenodo record 4010759)
- **Status**: âœ… Already downloaded and ready
- **Structure**: 30 words in category folders (Pronouns, Greetings, Adjectives, Days_and_Time, People, Colours, Animals, Objects_at_Home, Places)
- **Format**: Video files (1920x1080, 25fps, ~2.57 seconds each)
- **Vocabulary**: See provided CSV files with 30 words categorized by priority

***

## ðŸ› ï¸ TECHNICAL REQUIREMENTS

### 1. Data Preprocessing Module
- Extract frames from ISL videos
- Apply **MediaPipe** or OpenPose for hand landmark detection
- Normalize and augment data (rotation, scaling, brightness)
- Split: 70% train / 15% validation / 15% test
- Handle class imbalance
- Save preprocessed features (HDF5 or NPY format)

### 2. Sign Recognition Model
**Architecture Options** (choose best performing):
- **Option A**: CNN-LSTM (3D convolutions + temporal modeling)
- **Option B**: I3D (Inflated 3D ConvNet)
- **Option C**: Transformer-based (TimeSformer or VideoMAE)

**Requirements**:
- Input: Preprocessed video frames or hand landmarks
- Output: 30-class classification
- Metrics: Accuracy, Precision, Recall, F1-Score, Confusion Matrix
- Model checkpointing

### 3. Sentence Formation Transformer
- **Seq2Seq Transformer**: Word sequence â†’ Grammatical sentence
- Use attention mechanism for word order
- Handle missing words gracefully
- **Training**: Generate synthetic data from 30-word vocabulary combinations

**Example transformations**:
- `["I", "happy", "today"]` â†’ `"I am happy today"`
- `["she", "beautiful"]` â†’ `"She is beautiful"`
- `["hello", "friend"]` â†’ `"Hello, my friend"`

### 4. Real-time Inference Pipeline
- Video capture (webcam or file upload)
- Sliding window recognition
- Accumulate recognized words
- Pass to transformer for sentence generation
- Display with confidence scores

### 5. User Interface (Choose one)
- **Streamlit** â­ (recommended for quick deployment)
- **Gradio** (simple ML interface)
- **Flask/FastAPI + React** (production-ready)

**Features**:
- âœ… Video upload or webcam capture
- âœ… Real-time sign recognition display
- âœ… Word sequence visualization
- âœ… Generated sentence output
- âœ… Confidence scores
- âœ… Manual correction option
- âœ… Export recognized text

### 6. Model Training Scripts
- Data preprocessing and feature extraction
- Sign recognition model training + hyperparameter tuning
- Transformer sentence generation training
- Model evaluation and validation
- Use **config files** (YAML/JSON)
- Implement logging (TensorBoard or Weights & Biases)

### 7. Deployment & Packaging
- **Dockerize** the application
- Create `requirements.txt`
- Model versioning and experiment tracking
- Optimize for inference (quantization, pruning)
- API endpoints (optional)

***

## ðŸ’» TECHNOLOGY STACK

### Deep Learning
- PyTorch or TensorFlow/Keras
- Hugging Face Transformers
- OpenCV (video processing)
- MediaPipe or OpenPose

### Data & Utilities
- NumPy, Pandas
- Scikit-learn
- Matplotlib, Seaborn
- Albumentations (augmentation)

### Interface & Deployment
- Streamlit or Gradio
- Docker
- FastAPI (optional)
- Git/GitHub

***

## ðŸ“ PROJECT STRUCTURE

```
isl-recognition/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original INCLUDE dataset
â”‚   â”œâ”€â”€ processed/              # Preprocessed features
â”‚   â””â”€â”€ train_test_split/       # Train/val/test splits
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ sign_recognition/       # CNN-LSTM or I3D models
â”‚   â”œâ”€â”€ transformer/            # Sentence generation transformer
â”‚   â””â”€â”€ checkpoints/            # Saved model weights
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py   # Video preprocessing pipeline
â”‚   â”œâ”€â”€ train_recognition.py    # Train sign recognition model
â”‚   â”œâ”€â”€ train_transformer.py    # Train sentence transformer
â”‚   â”œâ”€â”€ inference.py            # Real-time inference engine
â”‚   â””â”€â”€ utils.py                # Helper functions
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ eda.ipynb              # Exploratory data analysis
â”‚   â”œâ”€â”€ model_experiments.ipynb # Model experiments
â”‚   â””â”€â”€ evaluation.ipynb        # Evaluation and metrics
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ streamlit_app.py       # Main UI application
â”‚   â””â”€â”€ api.py                 # API endpoints (optional)
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml            # Training configurations
â”‚   â””â”€â”€ model_config.yaml      # Model hyperparameters
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_*.py              # Unit tests
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

***

## ðŸ“‹ DELIVERABLES

1. âœ… **Complete Working Application** (all components integrated)
2. ðŸŽ¯ **Trained Models** (>85% accuracy target)
3. ðŸ“– **Documentation**:
   - README with setup instructions
   - API documentation
   - Model architecture diagrams
   - Training procedures
4. ðŸ““ **Jupyter Notebooks**:
   - Dataset exploration
   - Model training process
   - Results visualization
5. ðŸŽ¥ **Demo Video** showing application in action

***

## ðŸ—“ï¸ 10-DAY DEVELOPMENT WORKFLOW

### Phase 1: Data Preparation (Day 1-2)
- Load and explore INCLUDE dataset
- Implement preprocessing pipeline
- Extract features (frames or landmarks)
- Create train/val/test splits
- Verify data quality

### Phase 2: Sign Recognition Model (Day 3-5)
- Implement baseline model (CNN-LSTM)
- Train and validate
- Experiment with architectures
- Hyperparameter optimization
- Achieve >85% accuracy

### Phase 3: Transformer Development (Day 6-7)
- Generate synthetic training data
- Implement transformer encoder-decoder
- Train on word sequences â†’ sentences
- Evaluate and fine-tune

### Phase 4: Integration & UI (Day 8-9)
- Build inference pipeline
- Create Streamlit/Gradio interface
- Integrate recognition + transformer
- Real-time video processing
- End-to-end testing

### Phase 5: Testing & Deployment (Day 10)
- Comprehensive testing
- Bug fixes and optimization
- Docker containerization
- Documentation
- Demo preparation

***

## âœ… SUCCESS CRITERIA
- ðŸŽ¯ Sign recognition accuracy: **>85%** on test set
- ðŸ“ Transformer generates grammatically correct sentences: **>90%**
- âš¡ Real-time processing: **<2 seconds** latency per sign
- ðŸ’» User-friendly interface with clear visualizations
- ðŸ“š Well-documented, reproducible code
- ðŸ³ Deployable Docker container

***

## ðŸ“Œ ADDITIONAL NOTES
- Prioritize **CRITICAL** and **HIGH** priority words (17 words) initially
- Use **transfer learning** (pretrained I3D, VideoMAE)
- Implement **data augmentation**
- Add error handling and logging
- Make code modular and maintainable
- Handle edge cases (unclear signs, multiple signs)

## ðŸ“‚ REFERENCE FILES PROVIDED
- `ISL_30_words_complete.csv` - Complete vocabulary with metadata
- `ISL_30_words_by_priority.csv` - Priority-based grouping
- `ISL_30_words_by_category.csv` - Category-wise distribution

***

**ðŸš€ START**: Set up project structure â†’ Data preprocessing â†’ Build end-to-end pipeline â†’ Optimize components

***

## ðŸŽ¬ HOW TO USE THIS PROMPT

1. **Copy the entire prompt above**
2. **Open Windsurf AI coding assistant**
3. **Paste the prompt**
4. **Windsurf will**:
   - Create complete project structure
   - Generate all Python scripts
   - Set up configuration files
   - Implement models and pipelines
   - Create UI application
   - Add documentation

5. **Follow the 10-day workflow** for systematic development
