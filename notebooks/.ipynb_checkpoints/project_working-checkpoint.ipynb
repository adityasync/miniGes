{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sinGes-mini: Project Working Notebook\n",
    "\n",
    "- Activate virtual env before running: `pyenv activate miniGes` (see Roadmap.md).\n",
    "- Run cells top-to-bottom after configuring paths in `config/config.yaml`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup: add project root to sys.path and verify environment\n",
    "from pathlib import Path\n",
    "import sys, importlib\n",
    "\n",
    "# In notebooks, __file__ is not defined. Use CWD (notebooks/) -> parent is project root.\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR if NOTEBOOK_DIR.name != 'notebooks' else NOTEBOOK_DIR.parents[0]\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print('Project root:', PROJECT_ROOT)\n",
    "\n",
    "# Quick dependency check (prints versions if installed)\n",
    "def _check(pkg):\n",
    "    try:\n",
    "        m = importlib.import_module(pkg)\n",
    "        v = getattr(m, '__version__', 'n/a')\n",
    "        print(f'{pkg}:', v)\n",
    "    except Exception as e:\n",
    "        print(f'{pkg}: NOT FOUND ->', e)\n",
    "for p in ['torch','torchvision','opencv-python','mediapipe','transformers','numpy','pyyaml']:\n",
    "    # opencv-python's import name is cv2\n",
    "    name = 'cv2' if p=='opencv-python' else p\n",
    "    _check(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configs and utilities\n",
    "from src.utils import load_config, load_model_config, setup_logging, seed_everything, resolve_path\n",
    "config = load_config('config/config.yaml')\n",
    "model_cfg = load_model_config('config/model_config.yaml')\n",
    "setup_logging(config['paths'].get('logs_dir','logs'))\n",
    "seed_everything(config['project']['seed'])\n",
    "config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import discover_class_labels, strip_label_prefix\n",
    "dataset_root = resolve_path(config['paths']['dataset_root'])\n",
    "labels = discover_class_labels(dataset_root)\n",
    "display_labels = [strip_label_prefix(x) for x in labels]\n",
    "print('Labels discovered:', len(labels))\n",
    "display_labels[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Preprocess raw videos (frames + landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step scans dataset_root for videos and writes .npz to data/raw and mediapipe outputs if enabled.\n",
    "# Ensure mediapipe is installed, or set use_mediapipe=false in config.\n",
    "from src.data_preprocessing import PreprocessingConfig, DataPreprocessor\n",
    "pre_cfg = PreprocessingConfig.from_dict(config)\n",
    "pre = DataPreprocessor(pre_cfg)\n",
    "pre.process_dataset()\n",
    "print('Preprocessing complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train sign recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires CUDA per training script. Adjust config/training if needed.\n",
    "from src.train_recognition import train as train_sign_recognition\n",
    "results = train_sign_recognition()\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from src.inference import SignRecognizer\n",
    "ckpt_dir = resolve_path(config['paths']['recognition_checkpoint_dir'])\n",
    "# pick latest checkpoint file in the directory (expects a single .pt)\n",
    "candidates = sorted([p for p in ckpt_dir.glob('*.pt')], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert candidates, f'No checkpoint found in {ckpt_dir}. Run training first.'\n",
    "ckpt = candidates[0]\n",
    "print('Using checkpoint:', ckpt)\n",
    "rec = SignRecognizer(checkpoint_path=ckpt, config_path='config/config.yaml', model_config_path='config/model_config.yaml')\n",
    "# Provide a sample video path to test\n",
    "sample_video = Path('tmp/web_uploads').glob('*.mp4')\n",
    "sample_video = next(sample_video, None)\n",
    "assert sample_video is not None, 'Place a sample .mp4 in tmp/web_uploads to run this cell.'\n",
    "preds = rec.predict(sample_video, top_k=5)\n",
    "[(p.display_label, round(p.score,4)) for p in preds]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
